#### 2021-05
- Meta-Learning
    - Torchmeta: A Meta-Learning library for PyTorch [[arXiv](https://arxiv.org/abs/1909.06576)]
- Generative Models
    - Information Theory for Intelligent People [[paper](http://tuvalu.santafe.edu/~simon/it.pdf)]
    - Approximating discrete probability distributions with dependence trees [[IEEE](https://ieeexplore.ieee.org/document/1054142)]
- Reinforcement Learning
    - High-Dimensional Continuous Control Using Generalized Advantage Estimation [[arXiv](https://arxiv.org/abs/1506.02438)]


#### 2021-04
- Neural Architecture Search
    - Progressive DARTS: Bridging the Optimization Gap for NAS in the Wild [[arXiv](https://arxiv.org/abs/1912.10952)]
    - GOLD-NAS: Gradual, One-Level, Differentiable [[arXiv](https://arxiv.org/abs/2007.03331)]
    - Population Based Training of Neural Networks [[arXiv](https://arxiv.org/abs/1711.09846)]
    - EfficientPose: Efficient Human Pose Estimation with Neural Architecture Search [[arXiv](https://arxiv.org/abs/2012.07086)]
    - NAS evaluation is frustratingly hard [[arXiv](https://arxiv.org/abs/1912.12522)]
    - Weight-Sharing Neural Architecture Search: A Battle to Shrink the Optimization Gap [[arXiv](https://arxiv.org/abs/2008.01475)]
    - DARTS: Differentiable Architecture Search [[arXiv](https://arxiv.org/abs/1806.09055)]
    - UNAS: Differentiable Architecture Search Meets Reinforcement Learning [[arXiv](https://arxiv.org/abs/1912.07651)]
    - Hierarchical Representations for Efficient Architecture Search [[arXiv](https://arxiv.org/abs/1711.00436)]
- Meta-Learning
    - M-NAS: Meta Neural Architecture Search [[paper](https://ojs.aaai.org//index.php/AAAI/article/view/6084)]
    - Meta-Learning of Neural Architectures for Few-Shot Learning [[arXiv](https://arxiv.org/abs/1911.11090)]
    - Auto-Meta: Automated Gradient Based Meta Learner Search [[arXiv](https://arxiv.org/abs/1806.06927)]
- Computer Vision
    - U-Net: Convolutional Networks for Biomedical Image Segmentation [[arXiv](https://arxiv.org/abs/1505.04597)]
    - ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness [[arXiv](https://arxiv.org/abs/1811.12231)]
    - On Translation Invariance in CNNs: Convolutional Layers can Exploit Absolute Spatial Location [[arXiv](https://arxiv.org/abs/2003.07064)]
- Reinforcement Learning
    - Recurrent experience replay in distributed Reinforcement Learning [[paper](https://openreview.net/pdf?id=r1lyTjAqYX)]
    - Enhanced POET: Open-Ended Reinforcement Learning through Unbounded Invention of Learning Challenges and their Solutions [[arXiv](https://arxiv.org/abs/2003.08536) [blog](https://eng.uber.com/poet-open-ended-deep-learning/)]
    - Memory-based control with recurrent neural networks [[arXiv](https://arxiv.org/abs/1512.04455)]
    - Soft Actor-Critic Algorithms and Applications [[arXiv](https://arxiv.org/abs/1812.05905)]
    - Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor [[arXiv](https://arxiv.org/abs/1801.01290)]
- Can recurrent neural networks warp time? [[arXiv](https://arxiv.org/pdf/1804.11188.pdf)]

#### 2021-03
- Reinforcement Learning
    - Meta-World: A Benchmark and Evaluation for Multi-Task and Meta Reinforcement Learning [[arXiv](https://arxiv.org/abs/1910.10897)]
    - Scalable trust-region method for deep reinforcement learning using Kronecker-factored approximation [[arXiv](https://arxiv.org/abs/1708.05144)]
    - Asynchronous Methods for Deep Reinforcement Learning [[arXiv](https://arxiv.org/abs/1602.01783)]
    - Paired Open-Ended Trailblazer (POET): Endlessly Generating Increasingly Complex and Diverse Learning Environments and Their Solutions [[arXiv](https://arxiv.org/abs/1901.01753)]

#### 2021-02
- Meta-Learning
    - Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables [[arXiv](https://arxiv.org/abs/1903.08254)]

#### 2021-01
- Neural Architecture Search
    - A Comprehensive Survey of Neural Architecture Search: Challenges and Solutions [[arXiv](https://arxiv.org/abs/2006.02903)]

#### 2020-12
- Meta-Learning
    - Meta-Learning in Neural Networks: A Survey [[arXiv](https://arxiv.org/abs/2004.05439)]
- Reinforcement Learning
    - Asynchronous Methods for Deep Reinforcement Learning [[arXiv](https://arxiv.org/abs/1602.01783)]
    - Effective Policy Gradient Search for Reinforcement Learning Through NEAT Based Feature Extraction [[paper](https://link.springer.com/chapter/10.1007/978-3-319-68759-9_39)]
    - Random Error Sampling-based Recurrent Neural Network Architecture Optimization [[arXiv](https://arxiv.org/abs/1909.02425)]

#### 2020-11
- Reinforcement Learning
    - Human-level control through deep reinforcement learning [[paper](https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf)]
    - Deep Reinforcement Learning with Double Q-learning [[arXiv](https://arxiv.org/abs/1509.06461)]
    - Playing Atari with Deep Reinforcement Learning [[arXiv](https://arxiv.org/abs/1312.5602)]
    - Behavior Suite for Reinforcement Learning [[paper](https://arxiv.org/1908.03568)] 
- Statistical Modeling: The Two Cultures [[paper](http://www2.math.uu.se/~thulin/mm/breiman.pdf)]

#### 2020-10
- Meta-Learning
    - Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks [[arXiv](https://arxiv.org/abs/1703.03400)]
    - Meta-Dataset: A Dataset of Datasets for Learning to Learn from Few Examples [[arXiv](https://arxiv.org/abs/1903.03096)]
    - [Reinforcement Learning, Fast and Slow](notes/RL-fast-and-slow.md) [[cell](https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(19)30061-0)]
- The Bitter Lesson [[article](http://incompleteideas.net/IncIdeas/BitterLesson.html)]
- Weight Agnostic Neural Networks [[arXiv](https://arxiv.org/abs/1906.04358)] [[blog](https://gomerudo.github.io/ml-summaries/2020/03/09/wanns/)]

#### 2020-09
- [On First-Order Meta-Learning Algorithms](notes/First-order-meta-learning.md) [[arXiv](https://arxiv.org/abs/1801.02999)]
- [The Sorcererâ€™s Apprentice Guide to Training LSTMs](notes/Guide-to-training-LSTMs.md) [[blog](https://www.niklasschmidinger.com/posts/2020-09-09-lstm-tricks/)]
- [Learning to Reinforcement learn](notes/Learning-to-Reinforcement-learn.md) [[arXiv](https://arxiv.org/pdf/1611.05763.pdf)]
- [RL^2: Fast Reinforcement Learning via Slow Reinforcement Learning](notes/RL2-fast-rl-via-slow-rl.md) [[openReview](https://openreview.net/pdf?id=HkLXCE9lx)]
- [Practical Block-wise Neural Network Architecture Generation](notes/Block-NAS-generation.md) [[arXiv](https://arxiv.org/abs/1708.05552)]

#### 2020-08
- [Deep Reinforcement Learning: Pong from Pixels](notes/DRL-pong-from-pixels.md) [[blog](http://karpathy.github.io/2016/05/31/rl/)]
- [Exploration Strategies in Deep Reinforcement Learning](notes/Exploration-strats-in-DRL.md) [[blog](https://lilianweng.github.io/lil-log/2020/06/07/exploration-strategies-in-deep-reinforcement-learning.html)]
- [Learning to reinforcement learn for Neural Architecture Search](notes/Learn-2-learn-NAS.md) [[arXiv](https://arxiv.org/abs/1911.03769)]
- [Meta Reinforcement Learning](notes/MetaRL-lilian-blog.md) [[blog](https://lilianweng.github.io/lil-log/2019/06/23/meta-reinforcement-learning.html)]
- [Neural Architecture Search](notes/NAS-lilian-blog.md) [[blog](https://lilianweng.github.io/lil-log/2020/08/06/neural-architecture-search.html)]
